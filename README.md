# SVScope
Structural variation detection for short read via multi-source fusion and multi-channel visual filtering.

## 1. SVScope channel configuration:

```
conda config --add channels - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
conda config --add channels - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free
conda config --add channels defaults
conda config --add channels conda-forge
conda config --add channels bioconda
```

## 2. SVScope installation script:

```
./SVScope_install.sh
```

## 3. Reload .bashrc:

```
source ~/.bashrc
```

## 4. Activate the SVScope environment:

```
conda activate SVScope
```

## 5. Edit the scripts for the three algorithms into executable mode:

```
chmod +x Algorithm*.sh
```

## 6. Run SVScope_detect.sh to obtain the VCF file generated by SVScope but not filtered.

```
bash SVScope_detect.sh \
  --bam_path /your_path/your_bam_name.bam  \
  --referenceFasta /your_path/your_fa_name.fa \
  --out_dir /your_output_dir \
  --prefix /your_sample_name (eg.HG002) \
  --jobs thread_num(eg.4)
```

##### [Note: The three SV detection algorithms can also be called separately. If you do not want to use the multi-source integration command provided by SVScope, bash ./SVScope_detect.sh, you can also call the following three tools separately. All commands have been encapsulated, and you can call them directly by passing external parameters. The specific usage is as follows:]

##### For Algorithm1, the call command is:

```
bash Algorithm1.sh --bam_path /your_path/your_bam_name.bam 
					--referenceFasta /your_path/your_fa_name.fa
					--out_dir /your_output_dir
```

##### For Algorithm2, the call command is:

```
bash Algorithm2.sh --bam_path /your_path/your_bam_name.bam 
						--out_dir /your_output_dir
						--referenceFasta /your_path/your_fa_name.fa 
						--jobs thread_num(eg.4)
```

##### For Algorithm3, the call command is:

```
bash Algorithm3.sh --bam_path /your_path/your_bam_name.bam 
					--out_dir /your_output_dir
					--prefix /your_sample_name (eg.HG002)
```



## 7.SVScope_Filterï¼š

## Installation

```
conda env create -f SVScope_environment.yml
conda activate SVScope_filter
```

### Requirements

- Python 3.6                                                           

- Pytorch1.10.2

- Pysam 0.15.4

- numpy 1.19.5

- scikit-learn 0.24.2

- torchvision 0.11.3 

- tensorboard 2.8.0

- cudatookit 11.3.1

## Datasets

#### Reference

- hs37d5: https://ftp-trace.ncbi.nih.gov/1000genomes/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz
- hg19:http://hgdownload.cse.ucsc.edu/goldenPath/hg19/bigZips/chromFa.tar.gz

#### HG002

- Tier1 benchmark SV callset and high-confidence HG002 region: https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/analysis/NIST_SVs_Integration_v0.6/

- NHGRI_Illumina300X_AJtrio_novoalign_bam: https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/NIST_HiSeq_HG002_Homogeneity-10953946/NHGRI_Illumina300X_AJtrio_novoalign_bams/HG002.hs37d5.60x.1.bam
- NIST_Illumina_2x250bps/novoalign_bam: https://ftp.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG002_NA24385_son/NIST_Illumina_2x250bps/novoalign_bams/HG002.hs37d5.2x250.bam 
- NIST_BGIseq_2x150bp_100x_bam: https://ftp.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG002_NA24385_son/NIST_BGIseq_2x150bp_100x/GRCh37/HG002_GRCh37_BGIseq-2x150-100x_NIST_20211126.bam 

## Models that have been trained

| File name            | URL                                                          |
| -------------------- | ------------------------------------------------------------ |
| MobileNet_Attention  | https://github.com/nudt-bioinfo/SVScope/releases/download/v1.0.0/MobileNet_Attention.ckpt |
| ShuffleNet_Attention | https://github.com/nudt-bioinfo/SVScope/releases/download/v1.0.0/ShuffleNet_Attention.ckpt |
| ResNet34_Attention   | https://github.com/nudt-bioinfo/SVScope/releases/download/v1.0.0/ResNet34_Attention.ckpt |
| ResNet50_Attention   | https://github.com/nudt-bioinfo/SVScope/releases/download/v1.0.0/ResNet50_Attention.ckpt |

## Usage

### Train

In the src file

VCF data preprocessing:

```
python vcf_data_process.py
```

BAM data preprocessing:

```
python bam2depth.py
```

Parallel generate images:

```
python parallel_process_file.py --thread_num thread_num  
(python parallel_process_file.py --thread_num 8)
```

Check generated images:

```
python process_file_check.py
```

Rearrange generated images:

```
python data_spread.py
```

Train:

```
python train.py
```

### Predict & Filter

predict:

```
python predict.py selected_model
(e.g. python predict.py resnet50_Attention)
```

filter:
